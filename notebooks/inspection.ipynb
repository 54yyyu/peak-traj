{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5e7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JUPYTER_RUNTIME_DIR'] = os.path.expanduser('~/jupyter/runtime') \n",
    "os.makedirs(os.environ['JUPYTER_RUNTIME_DIR'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4a04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata as ad\n",
    "import scipy.sparse as sp\n",
    "from intervaltree import Interval, IntervalTree\n",
    "import gtfparse\n",
    "import os\n",
    "\n",
    "# For LSI (TF-IDF + SVD)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.io import mmwrite, mmread # Useful if dealing with matrix market files, though not directly needed for h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea73c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIR = \"../10x_pbmc\"\n",
    "ATAC_H5_FILE = os.path.join(DATA_DIR, \"atac_v1_pbmc_10k_filtered_peak_bc_matrix.h5\")\n",
    "GTF_FILE = os.path.join(DATA_DIR, \"Homo_sapiens.GRCh37.82.gtf\")\n",
    "ATAC_META_FILE = os.path.join(DATA_DIR, \"atac_v1_pbmc_10k_singlecell.csv\")\n",
    "RNA_H5AD_FILE = os.path.join(DATA_DIR, \"pbmc_10k_v3.h5ad\") # Assumed pre-processed h5ad file\n",
    "\n",
    "# Gene Activity Calculation Parameters\n",
    "UPSTREAM_KB = 2000\n",
    "SEQ_LEVELS = [str(i) for i in range(1, 23)] + [\"X\", \"Y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5920e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calculating Gene Activity Matrix...\n",
      "  Loading peak matrix: ../10x_pbmc/atac_v1_pbmc_10k_filtered_peak_bc_matrix.h5\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Gene Activity Quantification ---\n",
    "print(\"1. Calculating Gene Activity Matrix...\")\n",
    "\n",
    "peak_matrix_file, gtf_file, seq_levels, upstream = ATAC_H5_FILE, GTF_FILE, SEQ_LEVELS, UPSTREAM_KB\n",
    "\n",
    "\"\"\"\n",
    "Calculates a gene activity matrix from a peak matrix and GTF file.\n",
    "\n",
    "Args:\n",
    "    peak_matrix_file (str): Path to the 10x H5 peak matrix file.\n",
    "    gtf_file (str): Path to the GTF annotation file.\n",
    "    seq_levels (list): List of chromosomes/contigs to include.\n",
    "    upstream (int): Number of base pairs upstream of TSS to include.\n",
    "\n",
    "Returns:\n",
    "    anndata.AnnData: An AnnData object with genes as vars and cells as obs,\n",
    "                        containing the gene activity matrix in X.\n",
    "                        Also includes peak coordinates in .uns['peak_intervals']\n",
    "                        and the original peak matrix AnnData in .uns['peak_adata']\n",
    "                        for reference.\n",
    "\"\"\"\n",
    "print(f\"  Loading peak matrix: {peak_matrix_file}\")\n",
    "adata_peaks = sc.read_10x_h5(peak_matrix_file)\n",
    "adata_peaks.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be1296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading and parsing GTF: ../10x_pbmc/Homo_sapiens.GRCh37.82.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_version', 'gene_name', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'havana_transcript', 'havana_transcript_version', 'tag', 'exon_number', 'exon_id', 'exon_version', 'ccds_id', 'protein_id', 'protein_version']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of dimensions. values.ndim > ndim [2 > 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Loading and parsing GTF: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgtf_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Using gtfparse to read the GTF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m gtf = \u001b[43mgtfparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_gtf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgtf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Filter for genes on desired chromosomes\u001b[39;00m\n\u001b[32m      6\u001b[39m gtf_genes = gtf[gtf[\u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mgene\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/gtfparse/read_gtf.py:257\u001b[39m, in \u001b[36mread_gtf\u001b[39m\u001b[34m(filepath_or_buffer, expand_attribute_column, infer_biotype_column, column_converters, column_cast_types, usecols, features, result_type)\u001b[39m\n\u001b[32m    252\u001b[39m     result_df = parse_gtf(result_df, features=features)\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# converting back to pandas here because Polars bugs manifest\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# as `pyo3_runtime.PanicException: assertion `left == right` failed: impl error`\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# and are generally insane to chase down\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m result_df = \u001b[43mresult_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m column_converters \u001b[38;5;129;01mor\u001b[39;00m column_cast_types:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_to_always_accept_none\u001b[39m(f):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/polars/dataframe/frame.py:2093\u001b[39m, in \u001b[36mDataFrame.to_pandas\u001b[39m\u001b[34m(self, use_pyarrow_extension_array, **kwargs)\u001b[39m\n\u001b[32m   2088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Object \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtypes:\n\u001b[32m   2089\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._to_pandas_with_object_columns(\n\u001b[32m   2090\u001b[39m         use_pyarrow_extension_array=use_pyarrow_extension_array, **kwargs\n\u001b[32m   2091\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2093\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_pandas_without_object_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2094\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   2095\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/polars/dataframe/frame.py:2155\u001b[39m, in \u001b[36mDataFrame._to_pandas_without_object_columns\u001b[39m\u001b[34m(self, df, use_pyarrow_extension_array, **kwargs)\u001b[39m\n\u001b[32m   2147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tbl.to_pandas(\n\u001b[32m   2148\u001b[39m         self_destruct=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2149\u001b[39m         split_blocks=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2150\u001b[39m         types_mapper=\u001b[38;5;28;01mlambda\u001b[39;00m pa_dtype: pd.ArrowDtype(pa_dtype),\n\u001b[32m   2151\u001b[39m         **kwargs,\n\u001b[32m   2152\u001b[39m     )\n\u001b[32m   2154\u001b[39m date_as_object = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdate_as_object\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtbl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_as_object\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_as_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/array.pxi:884\u001b[39m, in \u001b[36mpyarrow.lib._PandasConvertible.to_pandas\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/table.pxi:4192\u001b[39m, in \u001b[36mpyarrow.lib.Table._to_pandas\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/pandas_compat.py:776\u001b[39m, in \u001b[36mtable_to_dataframe\u001b[39m\u001b[34m(options, table, categories, ignore_metadata, types_mapper)\u001b[39m\n\u001b[32m    774\u001b[39m _check_data_column_metadata_consistency(all_columns)\n\u001b[32m    775\u001b[39m columns = _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m blocks = \u001b[43m_table_to_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext_columns_dtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    778\u001b[39m axes = [columns, index]\n\u001b[32m    779\u001b[39m mgr = BlockManager(blocks, axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/pandas_compat.py:1131\u001b[39m, in \u001b[36m_table_to_blocks\u001b[39m\u001b[34m(options, block_table, categories, extension_columns)\u001b[39m\n\u001b[32m   1128\u001b[39m columns = block_table.column_names\n\u001b[32m   1129\u001b[39m result = pa.lib.table_to_blocks(options, block_table, categories,\n\u001b[32m   1130\u001b[39m                                 \u001b[38;5;28mlist\u001b[39m(extension_columns.keys()))\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m_reconstruct_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/pandas_compat.py:1131\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1128\u001b[39m columns = block_table.column_names\n\u001b[32m   1129\u001b[39m result = pa.lib.table_to_blocks(options, block_table, categories,\n\u001b[32m   1130\u001b[39m                                 \u001b[38;5;28mlist\u001b[39m(extension_columns.keys()))\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_reconstruct_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pyarrow/pandas_compat.py:739\u001b[39m, in \u001b[36m_reconstruct_block\u001b[39m\u001b[34m(item, columns, extension_columns)\u001b[39m\n\u001b[32m    737\u001b[39m     block = _int.make_block(pd_ext_arr, placement=placement)\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     block = \u001b[43m_int\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m block\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pandas/core/internals/api.py:93\u001b[39m, in \u001b[36mmake_block\u001b[39m\u001b[34m(values, placement, klass, ndim, dtype)\u001b[39m\n\u001b[32m     90\u001b[39m     values = extract_array(values, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     91\u001b[39m     values = ensure_block_shape(values, ndim)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mcheck_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m values = maybe_coerce_values(values)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m klass(values, ndim=ndim, placement=placement)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/insomnia001/depts/edu/COMSE6998/yy3448/mambaforge/envs/peak_traj/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2751\u001b[39m, in \u001b[36mcheck_ndim\u001b[39m\u001b[34m(values, placement, ndim)\u001b[39m\n\u001b[32m   2732\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2733\u001b[39m \u001b[33;03mndim inference and validation.\u001b[39;00m\n\u001b[32m   2734\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2746\u001b[39m \u001b[33;03mValueError : the number of dimensions do not match\u001b[39;00m\n\u001b[32m   2747\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2749\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m values.ndim > ndim:\n\u001b[32m   2750\u001b[39m     \u001b[38;5;66;03m# Check for both np.ndarray and ExtensionArray\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2751\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2752\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWrong number of dimensions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2753\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalues.ndim > ndim [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2754\u001b[39m     )\n\u001b[32m   2756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(values.dtype):\n\u001b[32m   2757\u001b[39m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[32m   2758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m values.ndim != ndim:\n",
      "\u001b[31mValueError\u001b[39m: Wrong number of dimensions. values.ndim > ndim [2 > 1]"
     ]
    }
   ],
   "source": [
    "print(f\"  Loading and parsing GTF: {gtf_file}\")\n",
    "# Using gtfparse to read the GTF\n",
    "gtf = gtfparse.read_gtf(gtf_file)\n",
    "\n",
    "# Filter for genes on desired chromosomes\n",
    "gtf_genes = gtf[gtf['feature'] == 'gene']\n",
    "gtf_genes = gtf_genes[gtf_genes['seqname'].isin(seq_levels)]\n",
    "print(f\"  Found {len(gtf_genes)} genes on specified seq levels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e25d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading and parsing GTF: ../10x_pbmc/Homo_sapiens.GRCh37.82.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474622/2105413042.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(gtf_file, sep='\\t', comment='#',\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Loading and parsing GTF: {gtf_file}\")\n",
    "# Read the GTF file directly with pandas\n",
    "gtf = pd.read_csv(gtf_file, sep='\\t', comment='#', \n",
    "                  names=['seqname', 'source', 'feature', 'start', 'end', \n",
    "                         'score', 'strand', 'frame', 'attribute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e49695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the attributes column (which contains key-value pairs)\n",
    "def parse_attributes(attr_str):\n",
    "    if pd.isna(attr_str):\n",
    "        return {}\n",
    "    attrs = {}\n",
    "    for attr in attr_str.split(';'):\n",
    "        if attr.strip():\n",
    "            try:\n",
    "                key, value = attr.strip().split(' ', 1)\n",
    "                attrs[key] = value.strip('\"')\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dad19e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Apply the function to extract attributes\n",
    "attr_dicts = gtf['attribute'].apply(parse_attributes)\n",
    "\n",
    "# Extract commonly used attributes\n",
    "common_attrs = ['gene_id', 'gene_name', 'gene_type', 'transcript_id']\n",
    "for attr in common_attrs:\n",
    "    gtf[attr] = attr_dicts.apply(lambda x: x.get(attr, None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24849c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading and parsing GTF: ../10x_pbmc/Homo_sapiens.GRCh37.82.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3474520/3091208214.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf = pd.read_csv(gtf_file, sep='\\t', comment='#',\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Filter for genes on desired chromosomes\n",
    "gtf_genes = gtf[gtf['feature'] == 'gene']\n",
    "gtf_genes = gtf_genes[gtf_genes['seqname'].isin(seq_levels)]\n",
    "print(f\"  Found {len(gtf_genes)} genes on specified seq levels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calculating Gene Activity Matrix...\n",
      "  Loading peak matrix: ../10x_pbmc/atac_v1_pbmc_10k_filtered_peak_bc_matrix.h5\n",
      "  Loading and parsing GTF: ../10x_pbmc/Homo_sapiens.GRCh37.82.gtf\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create interval trees for peaks\n",
    "peak_intervals = {}\n",
    "peak_mapping = {} # To map peak names back to indices in adata_peaks.var\n",
    "print(\"  Creating peak interval trees...\")\n",
    "for i, peak in enumerate(adata_peaks.var_names):\n",
    "    try:\n",
    "        chrom, coords = peak.split(':')\n",
    "        start, end = map(int, coords.split('-'))\n",
    "        if chrom not in peak_intervals:\n",
    "            peak_intervals[chrom] = IntervalTree()\n",
    "        peak_intervals[chrom][start:end] = i # Store index\n",
    "        peak_mapping[peak] = i\n",
    "    except ValueError:\n",
    "        print(f\"    Warning: Could not parse peak coordinates: {peak}\")\n",
    "        continue\n",
    "\n",
    "# Create gene activity matrix (sparse)\n",
    "gene_activity_matrix = sp.lil_matrix((len(gtf_genes), adata_peaks.n_obs), dtype=np.float32)\n",
    "gene_names = []\n",
    "gene_coords = {} # Store gene coords for reference\n",
    "\n",
    "print(\"  Matching peaks to genes...\")\n",
    "processed_genes = 0\n",
    "for idx, gene in gtf_genes.iterrows():\n",
    "    gene_id = gene['gene_id']\n",
    "    gene_name = gene['gene_name'] if 'gene_name' in gene and pd.notna(gene['gene_name']) else gene_id\n",
    "    chrom = gene['seqname']\n",
    "    start = gene['start']\n",
    "    end = gene['end']\n",
    "    strand = gene['strand']\n",
    "\n",
    "    # Define gene body region (+ upstream)\n",
    "    if strand == '+':\n",
    "        region_start = max(0, start - upstream)\n",
    "        region_end = end\n",
    "    else: # strand == '-'\n",
    "        region_start = start\n",
    "        region_end = end + upstream\n",
    "\n",
    "    gene_names.append(gene_name) # Use gene_name if available\n",
    "    gene_coords[gene_name] = f\"{chrom}:{region_start}-{region_end}\"\n",
    "\n",
    "    # Find overlapping peaks\n",
    "    if chrom in peak_intervals:\n",
    "        overlapping_peaks = peak_intervals[chrom][region_start:region_end]\n",
    "        if overlapping_peaks:\n",
    "            peak_indices = [p.data for p in overlapping_peaks]\n",
    "            # Sum counts for these peaks across all cells\n",
    "            gene_activity_vector = adata_peaks[:, peak_indices].X.sum(axis=1)\n",
    "            # Add to the sparse matrix\n",
    "            gene_activity_matrix[processed_genes, :] = gene_activity_vector.T # Assign the dense row\n",
    "\n",
    "    processed_genes += 1\n",
    "    if processed_genes % 1000 == 0:\n",
    "        print(f\"    Processed {processed_genes}/{len(gtf_genes)} genes...\")\n",
    "\n",
    "print(\"  Finalizing gene activity matrix...\")\n",
    "# Convert to CSR format for efficiency\n",
    "gene_activity_matrix = gene_activity_matrix.tocsr()\n",
    "\n",
    "# Create AnnData object for gene activity\n",
    "adata_activity = ad.AnnData(gene_activity_matrix.T) # Cells x Genes\n",
    "adata_activity.var_names = gene_names\n",
    "adata_activity.obs_names = adata_peaks.obs_names\n",
    "\n",
    "# Make gene names unique if duplicates exist\n",
    "adata_activity.var_names_make_unique()\n",
    "\n",
    "# Add peak info to .uns for potential future use\n",
    "adata_activity.uns['peak_intervals'] = peak_intervals\n",
    "adata_activity.uns['peak_adata_var_names'] = adata_peaks.var_names.tolist() # Store original peak names\n",
    "adata_activity.uns['gene_coords'] = gene_coords\n",
    "\n",
    "print(\"Gene Activity Calculation Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Object Setup and QC ---\n",
    "print(\"\\n2. Setting up AnnData Object and QC...\")\n",
    "\n",
    "# Create the main AnnData object using the peak matrix initially\n",
    "# We will store gene activity in a layer\n",
    "pbmc_atac = adata_peaks_orig.copy()\n",
    "pbmc_atac.layers[\"activity\"] = adata_activity[pbmc_atac.obs_names, :].X.T # Ensure cells match and shape is peaks x cells\n",
    "\n",
    "# Load metadata\n",
    "meta = pd.read_csv(ATAC_META_FILE, index_col=0)\n",
    "\n",
    "# Align metadata with the AnnData object\n",
    "common_barcodes = pbmc_atac.obs_names.intersection(meta.index)\n",
    "print(f\"  Found {len(common_barcodes)} barcodes common between matrix and metadata.\")\n",
    "pbmc_atac = pbmc_atac[common_barcodes, :].copy()\n",
    "meta = meta.loc[common_barcodes, :]\n",
    "\n",
    "# Add metadata to AnnData object\n",
    "for col in meta.columns:\n",
    "    pbmc_atac.obs[col] = meta[col]\n",
    "\n",
    "# QC: Filter cells with fewer than 5K total counts in the ATAC data\n",
    "# Seurat's nCount_ATAC corresponds to the sum of counts per cell in the *peak* matrix\n",
    "sc.pp.calculate_qc_metrics(pbmc_atac, qc_vars=['atac'], percent_top=None, log1p=False, inplace=True) # calculates n_genes_by_counts, total_counts\n",
    "# Rename 'total_counts' to match the vignette's 'nCount_ATAC' for clarity\n",
    "pbmc_atac.obs['nCount_ATAC'] = pbmc_atac.obs['total_counts']\n",
    "\n",
    "n_cells_before = pbmc_atac.n_obs\n",
    "pbmc_atac = pbmc_atac[pbmc_atac.obs['nCount_ATAC'] > 5000, :]\n",
    "print(f\"  Filtered cells based on nCount_ATAC > 5000. Kept {pbmc_atac.n_obs} out of {n_cells_before} cells.\")\n",
    "\n",
    "# Add technology label\n",
    "pbmc_atac.obs['tech'] = 'atac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Preprocessing (Gene Activity) ---\n",
    "print(\"\\n3. Preprocessing Gene Activity Matrix...\")\n",
    "\n",
    "# Create a temporary AnnData with activity matrix for processing\n",
    "adata_activity_proc = ad.AnnData(pbmc_atac.layers[\"activity\"].T) # Genes x Cells -> Cells x Genes\n",
    "adata_activity_proc.obs_names = pbmc_atac.obs_names\n",
    "adata_activity_proc.var_names = adata_activity.var_names # Use original gene names from calculation\n",
    "\n",
    "# Basic processing for gene activity matrix - required for finding anchors\n",
    "sc.pp.highly_variable_genes(adata_activity_proc, n_top_genes=4000, flavor='seurat_v3')\n",
    "sc.pp.normalize_total(adata_activity_proc, target_sum=1e4)\n",
    "sc.pp.log1p(adata_activity_proc)\n",
    "sc.pp.scale(adata_activity_proc, max_value=10)\n",
    "\n",
    "# Store the processed activity data back (or keep adata_activity_proc separate)\n",
    "# For simplicity, let's store the HVG info and scaled data back into the main object\n",
    "pbmc_atac.var['highly_variable_activity'] = adata_activity_proc.var['highly_variable']\n",
    "# Note: Scanpy's scale overwrites .X. If needed later, store scaled data in a layer\n",
    "# pbmc_atac.layers['activity_scaled'] = adata_activity_proc.X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385636da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Data Preprocessing (Peak Matrix - LSI) ---\n",
    "print(\"\\n4. Preprocessing Peak Matrix (LSI)...\")\n",
    "\n",
    "# Filter peaks: Keep peaks present in at least 100 cells\n",
    "min_cells_per_peak = 100\n",
    "sc.pp.filter_genes(pbmc_atac, min_cells=min_cells_per_peak) # filter genes (peaks) based on cells\n",
    "print(f\"  Filtered peaks. Kept {pbmc_atac.n_vars} peaks present in > {min_cells_per_peak} cells.\")\n",
    "\n",
    "# LSI Implementation (TF-IDF followed by SVD)\n",
    "print(\"  Calculating TF-IDF...\")\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "# Needs features (peaks) x samples (cells)\n",
    "tfidf_matrix = tfidf.fit_transform(pbmc_atac.X.T) # Transpose to get peaks x cells\n",
    "\n",
    "# Reduce dimensionality using SVD (LSI)\n",
    "n_components = 50 # As used in the vignette (dims 2 to 50 are often used, skipping first)\n",
    "print(f\"  Running TruncatedSVD (LSI) with {n_components} components...\")\n",
    "svd = TruncatedSVD(n_components=n_components, algorithm='arpack', random_state=42)\n",
    "lsi_matrix = svd.fit_transform(tfidf_matrix) # Result is peaks x components\n",
    "\n",
    "# The resulting components are analogous to PCA components.\n",
    "# We need cell embeddings (cells x components).\n",
    "# In LSI, cell embeddings are often derived differently, sometimes V.T * Sigma\n",
    "# However, a common practical approach is to use the transform of the original matrix\n",
    "# Let's project the cells onto the components found: cells x components\n",
    "# Note: Seurat RunLSI V.T is the cell embedding (cells x components)\n",
    "# lsi_cell_embeddings = tfidf_matrix.T @ svd.components_.T # Doesn't seem right dimensionally\n",
    "lsi_cell_embeddings = svd.transform(tfidf_matrix.T) # Project cell vectors (tfidf) onto components\n",
    "\n",
    "# Store LSI results in AnnData object (cells x components)\n",
    "pbmc_atac.obsm['X_lsi'] = lsi_cell_embeddings\n",
    "\n",
    "# Run UMAP on LSI components\n",
    "print(\"  Running UMAP on LSI components...\")\n",
    "# Use components 2 to 50 (index 1 to 49) as often the first component captures technical variation/depth\n",
    "sc.pp.neighbors(pbmc_atac, n_neighbors=30, use_rep='X_lsi', n_pcs=n_components, key_added='lsi_neighbors') # Use all components for neighbor graph\n",
    "sc.tl.umap(pbmc_atac, min_dist=0.3, neighbors_key='lsi_neighbors')\n",
    "# Store this UMAP separately\n",
    "pbmc_atac.obsm['X_umap_lsi'] = pbmc_atac.obsm['X_umap']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89856a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Load scRNA-seq Data ---\n",
    "print(\"\\n5. Loading pre-processed scRNA-seq data...\")\n",
    "try:\n",
    "    pbmc_rna = sc.read_h5ad(RNA_H5AD_FILE)\n",
    "    pbmc_rna.obs['tech'] = 'rna'\n",
    "    print(\"  scRNA-seq data loaded successfully.\")\n",
    "    # Assume pbmc_rna has 'celltype' in .obs and 'X_umap' in .obsm\n",
    "    # Ensure variable genes are marked if not already\n",
    "    if 'highly_variable' not in pbmc_rna.var.columns:\n",
    "         print(\"  Warning: 'highly_variable' not found in RNA data, calculating again...\")\n",
    "         sc.pp.highly_variable_genes(pbmc_rna, n_top_genes=4000, flavor='seurat_v3') # Use same params as activity\n",
    "except FileNotFoundError:\n",
    "    print(f\"  Error: RNA data file not found at {RNA_H5AD_FILE}. Cannot proceed with integration.\")\n",
    "    pbmc_rna = None\n",
    "except Exception as e:\n",
    "    print(f\"  Error loading RNA data: {e}. Cannot proceed with integration.\")\n",
    "    pbmc_rna = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34833a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Visualize Initial Embeddings ---\n",
    "if pbmc_rna is not None:\n",
    "    print(\"\\n6. Visualizing initial UMAP embeddings...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    sc.pl.umap(pbmc_atac, color='tech', ax=axes[0], show=False, title=\"scATAC-seq (LSI UMAP)\", use_raw=False, basis='umap_lsi')\n",
    "    sc.pl.umap(pbmc_rna, color='celltype', ax=axes[1], show=False, title=\"scRNA-seq (RNA UMAP)\", legend_loc='on data', legend_fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02039717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Identify Anchors and Transfer Labels ---\n",
    "# Scanpy uses 'ingest' for mapping/label transfer, conceptually similar to FindTransferAnchors + TransferData\n",
    "if pbmc_rna is not None:\n",
    "    print(\"\\n7. Transferring Cell Type Labels using Scanpy Ingest...\")\n",
    "\n",
    "    # Ensure RNA data has PCA calculated, as ingest uses it by default\n",
    "    if 'X_pca' not in pbmc_rna.obsm:\n",
    "        print(\"  Calculating PCA for RNA data (required for ingest)...\")\n",
    "        sc.tl.pca(pbmc_rna, svd_solver='arpack', use_highly_variable=True)\n",
    "\n",
    "    # --- Re-aligning ATAC data for Ingest ---\n",
    "    # Ingest requires the query object (ATAC) to have data for the features used in the reference (RNA).\n",
    "    # The vignette uses the 'ACTIVITY' assay (gene activity). We need an AnnData for ATAC\n",
    "    # containing the *unscaled* log-normalized gene activity for the *variable genes* of the RNA reference.\n",
    "\n",
    "    # 1. Get variable genes from RNA reference\n",
    "    var_genes_rna = pbmc_rna.var_names[pbmc_rna.var['highly_variable']]\n",
    "    print(f\"  Using {len(var_genes_rna)} variable genes from RNA reference.\")\n",
    "\n",
    "    # 2. Create ATAC AnnData with log-normalized activity for these genes\n",
    "    # Use the original activity matrix stored in pbmc_atac.layers['activity']\n",
    "    common_genes = pbmc_atac.layers['activity'].var_names.intersection(var_genes_rna)\n",
    "    print(f\"  Found {len(common_genes)} common variable genes in ATAC activity matrix.\")\n",
    "\n",
    "    adata_atac_activity_for_ingest = ad.AnnData(pbmc_atac.layers['activity'][:, common_genes].T) # Cells x Genes\n",
    "    adata_atac_activity_for_ingest.obs = pbmc_atac.obs.copy()\n",
    "    adata_atac_activity_for_ingest.obsm['X_lsi'] = pbmc_atac.obsm['X_lsi'] # Carry over LSI for weight reduction\n",
    "\n",
    "    # 3. Normalize and log-transform this specific matrix\n",
    "    sc.pp.normalize_total(adata_atac_activity_for_ingest, target_sum=1e4)\n",
    "    sc.pp.log1p(adata_atac_activity_for_ingest)\n",
    "\n",
    "    # --- Run Ingest ---\n",
    "    # reference.assay = \"RNA\", query.assay = \"ACTIVITY\" -> Use RNA PCA space and ATAC activity data\n",
    "    # reduction = \"cca\" -> Ingest uses PCA space of reference by default\n",
    "    # weight.reduction = pbmc.atac[[\"lsi\"]] -> Pass LSI embedding via `obsm_key`\n",
    "    print(\"  Running sc.tl.ingest...\")\n",
    "    sc.tl.ingest(\n",
    "        adata_atac_activity_for_ingest, # Query (ATAC activity)\n",
    "        pbmc_rna,                       # Reference (RNA)\n",
    "        obs='celltype',                 # Column to transfer\n",
    "        embedding_basis='pca',          # Map to reference PCA space\n",
    "        obsm_key='X_lsi',               # Use ATAC LSI for weighting (analogous to weight.reduction)\n",
    "        inplace=True                    # Add results to adata_atac_activity_for_ingest\n",
    "    )\n",
    "\n",
    "    # Transfer results back to the main ATAC object\n",
    "    pbmc_atac.obs['predicted_id'] = adata_atac_activity_for_ingest.obs['celltype']\n",
    "    # Ingest provides probabilities in .uns['ingest']['celltype_probabilities']\n",
    "    # Find the max probability for each cell\n",
    "    transfer_probabilities = adata_atac_activity_for_ingest.uns['ingest']['celltype_probabilities']\n",
    "    pbmc_atac.obs['prediction_score_max'] = transfer_probabilities.max(axis=1)\n",
    "\n",
    "    print(\"  Label transfer complete.\")\n",
    "\n",
    "    # --- Evaluate Transfer ---\n",
    "    print(\"  Evaluating transfer prediction scores...\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(pbmc_atac.obs['prediction_score_max'], bins=50)\n",
    "    plt.axvline(0.5, color='red', linestyle='--')\n",
    "    plt.title(\"Prediction Score Distribution\")\n",
    "    plt.xlabel(\"Max Prediction Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    score_threshold = 0.5\n",
    "    pass_threshold = pbmc_atac.obs['prediction_score_max'] > score_threshold\n",
    "    print(f\"  Cells passing threshold ({score_threshold}): {pass_threshold.sum()} / {pbmc_atac.n_obs}\")\n",
    "\n",
    "    # Filter ATAC data based on prediction score\n",
    "    pbmc_atac_filtered = pbmc_atac[pass_threshold, :].copy()\n",
    "\n",
    "    # Ensure factor levels match for consistent plotting colors\n",
    "    pbmc_atac_filtered.obs['predicted_id'] = pd.Categorical(\n",
    "        pbmc_atac_filtered.obs['predicted_id'],\n",
    "        categories=pbmc_rna.obs['celltype'].cat.categories,\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # --- Visualize Transferred Labels ---\n",
    "    print(\"  Visualizing transferred labels on ATAC UMAP...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    sc.pl.umap(\n",
    "        pbmc_atac_filtered,\n",
    "        color='predicted_id',\n",
    "        ax=axes[0],\n",
    "        show=False,\n",
    "        title=\"scATAC-seq Cells (Predicted ID)\",\n",
    "        legend_loc='on data',\n",
    "        legend_fontsize=8,\n",
    "        basis='umap_lsi' # Use the LSI-based UMAP\n",
    "    )\n",
    "    sc.pl.umap(\n",
    "        pbmc_rna,\n",
    "        color='celltype',\n",
    "        ax=axes[1],\n",
    "        show=False,\n",
    "        title=\"scRNA-seq Cells (Ground Truth)\",\n",
    "        legend_loc='on data',\n",
    "        legend_fontsize=8\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Co-embedding ---\n",
    "# The vignette uses TransferData again to impute RNA values into ATAC cells, then merges.\n",
    "# Scanpy's ingest primarily maps cells and transfers labels.\n",
    "# A common Scanpy approach for co-visualization is to:\n",
    "# 1. Concatenate the objects.\n",
    "# 2. Use a common feature space (e.g., variable genes).\n",
    "# 3. Run PCA/Neighbors/UMAP on the integrated object, possibly after batch correction (e.g., Harmony, BBKNN).\n",
    "\n",
    "# Let's follow the vignette's *structure* more closely using ingest's mapping capability.\n",
    "# We'll project ATAC cells into the RNA's PCA space using ingest, then combine these\n",
    "# embeddings and run UMAP. This avoids direct imputation but achieves co-visualization.\n",
    "\n",
    "if pbmc_rna is not None:\n",
    "    print(\"\\n8. Co-embedding RNA and ATAC data...\")\n",
    "\n",
    "    # 1. Project ATAC activity data into RNA PCA space using ingest (already done partially above)\n",
    "    # We need the coordinates from `adata_atac_activity_for_ingest.obsm['X_pca']`\n",
    "    atac_projected_pca = adata_atac_activity_for_ingest.obsm['X_pca']\n",
    "\n",
    "    # 2. Create a combined AnnData object\n",
    "    # Ensure both objects use the same index type\n",
    "    pbmc_rna.obs_names = pbmc_rna.obs_names.astype(str)\n",
    "    pbmc_atac.obs_names = pbmc_atac.obs_names.astype(str)\n",
    "\n",
    "    # Select only the common obs (cells) that were processed and potentially filtered\n",
    "    common_atac_cells = pbmc_atac.obs_names.intersection(adata_atac_activity_for_ingest.obs_names)\n",
    "    pbmc_atac_subset = pbmc_atac[common_atac_cells, :].copy()\n",
    "    atac_projected_pca_subset = adata_atac_activity_for_ingest[common_atac_cells, :].obsm['X_pca']\n",
    "\n",
    "    # Important: Concatenation requires shared variables or handling differences.\n",
    "    # Since we're primarily interested in using the embeddings, we'll build\n",
    "    # a new AnnData containing the combined embeddings.\n",
    "\n",
    "    # Create combined PCA matrix (RNA PCA + ATAC projected PCA)\n",
    "    combined_pca = np.vstack((pbmc_rna.obsm['X_pca'], atac_projected_pca_subset))\n",
    "\n",
    "    # Create combined metadata\n",
    "    obs_rna = pbmc_rna.obs[['tech', 'celltype']].copy()\n",
    "    obs_atac = pbmc_atac_subset.obs[['tech', 'predicted_id']].copy()\n",
    "    obs_atac.rename(columns={'predicted_id': 'celltype'}, inplace=True) # Use predicted ID as celltype for ATAC\n",
    "\n",
    "    combined_obs = pd.concat([obs_rna, obs_atac], axis=0)\n",
    "\n",
    "    # Create the co-embedding AnnData object\n",
    "    coembed = ad.AnnData(obs=combined_obs)\n",
    "    coembed.obsm['X_pca_integrated'] = combined_pca # Store the combined PCA data\n",
    "\n",
    "    print(\"  Running UMAP on combined PCA representation...\")\n",
    "    # Run Neighbors and UMAP on the integrated PCA\n",
    "    sc.pp.neighbors(coembed, use_rep='X_pca_integrated', n_neighbors=30, key_added='coembed_neighbors')\n",
    "    sc.tl.umap(coembed, min_dist=0.3, neighbors_key='coembed_neighbors')\n",
    "\n",
    "    # --- Visualize Co-embedding ---\n",
    "    print(\"  Visualizing co-embedding...\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    sc.pl.umap(coembed, color='tech', ax=axes[0], show=False, title=\"Co-embedding by Technology\")\n",
    "    sc.pl.umap(coembed, color='celltype', ax=axes[1], show=False, title=\"Co-embedding by Cell Type\",\n",
    "               legend_loc='on data', legend_fontsize=8, na_color='lightgrey') # Show predicted for ATAC\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping steps 6, 7, 8 because scRNA-seq data could not be loaded.\")\n",
    "\n",
    "print(\"\\nScript Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
